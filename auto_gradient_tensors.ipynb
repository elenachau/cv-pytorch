{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e7ac42",
   "metadata": {},
   "source": [
    "### How to Calculate Gradients of a Tensor Object with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b9665a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2., -1.],\n",
      "        [ 1.,  1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# define tensor object\n",
    "import torch\n",
    "x = torch.tensor([[2., -1.], [1., 1.]], requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dab6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = x.pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0bc454",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward() # find gradient of a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a4ddeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4., -2.],\n",
       "        [ 2.,  2.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get gradient of out with respect to x\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d258a4",
   "metadata": {},
   "source": [
    "#### Computing gradients from chain_rule.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1,1]])\n",
    "y = np.array([[0]])\n",
    "x, y = [torch.tensor(i).float() for i in (x,y)] # convert to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db12bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "W = [\n",
    "    np.array([[-0.0053, 0.3793],\n",
    "              [-0.5820, -0.5204],\n",
    "              [-0.2723, 0.1896]], dtype=np.float32).T, \n",
    "    np.array([-0.0140, 0.5607, -0.0628], dtype=np.float32), \n",
    "    np.array([[ 0.1528, -0.1745, -0.1135]], dtype=np.float32).T, \n",
    "    np.array([-0.5516], dtype=np.float32)\n",
    "]\n",
    "\n",
    "W = [torch.tensor(i, requires_grad=True) for i in W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f71dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(inputs, outputs, weights):\n",
    "    # calculate hidden layers\n",
    "    pre_hidden = torch.matmul(inputs, weights[0]) + weights[1] # weight[0] (weight values) and weight[1] (bias terms)\n",
    "\n",
    "    hidden = 1/(1+torch.exp(-pre_hidden)) # apply non-linearity activation\n",
    "    pred_out = torch.matmul(hidden, weights[2]) + weights[3] # calc output layer values\n",
    "\n",
    "    # calc mean squared error value across dataset\n",
    "    mean_squared_error = torch.mean(torch.square(pred_out - outputs))\n",
    "\n",
    "    return mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c259e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3346, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = feed_forward(x, y, W)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41872b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0aa9267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.0428,  0.0469,  0.0327],\n",
      "        [-0.0428,  0.0469,  0.0327]]), tensor([-0.0428,  0.0469,  0.0327]), tensor([[-0.6814],\n",
      "        [-0.4255],\n",
      "        [-0.5364]]), tensor([-1.1568])]\n"
     ]
    }
   ],
   "source": [
    "print([w.grad for w in W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "693ae46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0375, -0.6289, -0.3050],\n",
       "         [ 0.4221, -0.5673,  0.1569]], grad_fn=<SubBackward0>),\n",
       " tensor([ 0.0288,  0.5138, -0.0955], grad_fn=<SubBackward0>),\n",
       " tensor([[0.8342],\n",
       "         [0.2510],\n",
       "         [0.4229]], grad_fn=<SubBackward0>),\n",
       " tensor([0.6052], grad_fn=<SubBackward0>)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_W = [w-w.grad for w in W]\n",
    "updated_W"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
